<!DOCTYPE html>
<html lang="en">
  <head>
    <!-- ============================================================================
       META TAGS
       ============================================================================ -->
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta
      name="description"
      content="Louise Ferreira's AI and machine learning projects - from fairness in adult content classification to cultural data mining and chatbot development."
    />
    <meta
      name="keywords"
      content="AI projects, machine learning, algorithmic fairness, NLP, cinema analysis, chatbot development"
    />
    <meta name="author" content="Louise Ferreira" />

    <title>Projects - Louise Ferreira</title>

    <!-- ============================================================================
       FONTS
       ============================================================================ -->
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Playfair+Display:wght@600;700&family=Inter:wght@400;500;600;700&display=swap"
      rel="stylesheet"
    />

    <!-- ============================================================================
       STYLESHEETS
       ============================================================================ -->
    <link rel="stylesheet" href="assets/css/main.css" />
    <link rel="stylesheet" href="assets/css/theme.css" />
    <link rel="stylesheet" href="assets/css/navbar.css" />
    <link rel="stylesheet" href="assets/css/projects.css" />
  </head>

  <body>
    <!-- ============================================================================
       SKIP LINK
       ============================================================================ -->
    <a href="#main-content" class="skip-link">Skip to main content</a>

    <!-- ============================================================================
       NAVIGATION BAR
       ============================================================================ -->
    <header class="site-header">
      <nav class="navbar" role="navigation" aria-label="Main navigation">
        <a href="index.html" class="navbar-brand">
          <span>Louise Ferreira</span>
        </a>

        <ul class="navbar-menu" role="list">
          <li><a href="index.html">Home</a></li>
          <li><a href="about.html">About</a></li>
          <li><a href="projects.html" class="active">Projects</a></li>
          <li><a href="skills.html">Skills</a></li>
          <li><a href="awards.html">Awards</a></li>
          <li><a href="personal.html">Personal</a></li>
          <li><a href="contact.html">Contact</a></li>

          <li class="navbar-social">
            <a
              href="https://github.com/louiseluli"
              target="_blank"
              rel="noopener noreferrer"
              aria-label="GitHub profile (opens in new tab)"
            >
              <svg
                xmlns="http://www.w3.org/2000/svg"
                viewBox="0 0 24 24"
                fill="none"
                stroke="currentColor"
                stroke-width="2"
                stroke-linecap="round"
                stroke-linejoin="round"
              >
                <path
                  d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"
                ></path>
              </svg>
            </a>

            <a
              href="https://www.linkedin.com/in/louisesfer/"
              target="_blank"
              rel="noopener noreferrer"
              aria-label="LinkedIn profile (opens in new tab)"
            >
              <svg
                xmlns="http://www.w3.org/2000/svg"
                viewBox="0 0 24 24"
                fill="none"
                stroke="currentColor"
                stroke-width="2"
                stroke-linecap="round"
                stroke-linejoin="round"
              >
                <path
                  d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"
                ></path>
                <rect x="2" y="9" width="4" height="12"></rect>
                <circle cx="4" cy="4" r="2"></circle>
              </svg>
            </a>
          </li>
        </ul>

        <button
          class="navbar-toggle"
          aria-label="Toggle navigation menu"
          aria-expanded="false"
        >
          <span></span>
          <span></span>
          <span></span>
        </button>
      </nav>
    </header>

    <!-- ============================================================================
       MAIN CONTENT
       ============================================================================ -->
    <main id="main-content" class="main-content">
      <!-- ==========================================================================
         PAGE HEADER
         ========================================================================== -->
      <section class="page-header">
        <div class="container">
          <h1 class="page-title" data-aos="fade-up">Projects That Matter</h1>
          <p class="page-subtitle" data-aos="fade-up" data-aos-delay="100">
            Where code meets conscience ‚Äî building AI that doesn't suck for
            marginalized people
          </p>
        </div>
      </section>

      <!-- ==========================================================================
         FILTER SECTION
         ========================================================================== -->
      <section class="filter-section">
        <div class="container">
          <div class="filter-controls" data-aos="fade-up">
            <button class="filter-btn active" data-filter="all">
              All Projects
            </button>
            <button class="filter-btn" data-filter="fairness">
              Algorithmic Fairness
            </button>
            <button class="filter-btn" data-filter="ml">
              Machine Learning
            </button>
            <button class="filter-btn" data-filter="nlp">
              NLP & Data Mining
            </button>
            <button class="filter-btn" data-filter="tools">
              AI Tools & Infrastructure
            </button>
          </div>
        </div>
      </section>

      <!-- ==========================================================================
     FEATURED PROJECT: MSc DISSERTATION
     ========================================================================== -->
      <section class="featured-project section" data-category="fairness ml">
        <div class="container">
          <div class="featured-badge" data-aos="fade-up">
            <span>üî¨ MSc Dissertation Research</span>
          </div>

          <div class="featured-content">
            <!-- Main Content Column -->
            <div class="featured-text" data-aos="fade-right">
              <h2 class="project-title">
                Fairness in Adult Content Classification Systems
              </h2>
              <p class="project-tagline">
                Quantifying and mitigating intersectional bias in ML-driven
                content moderation
              </p>

              <!-- Content Warning -->
              <div class="content-warning">
                <div class="content-warning-title">
                  ‚ö†Ô∏è Research Content Note
                </div>
                <p>
                  This research analyzes adult content metadata to study
                  algorithmic bias. No explicit imagery is displayed. All
                  analysis follows strict ethical guidelines and focuses on
                  fairness metrics, not content itself.
                </p>
              </div>

              <!-- Executive Summary -->
              <div class="executive-summary">
                <h3>Why This Research Matters</h3>
                <p>
                  Content moderation algorithms systematically discriminate
                  against LGBT creators, sex workers, and BIPOC communities.
                  When your ML model decides what's "appropriate," it's encoding
                  cultural biases at industrial scale ‚Äî and the people getting
                  hurt are always the same: queer folks, Black and Brown
                  creators, anyone outside the cishet white norm.
                </p>
                <p>
                  This thesis proves this discrimination is
                  <strong>measurable</strong>, <strong>quantifiable</strong>,
                  and most importantly ‚Äî <strong>fixable</strong>.
                </p>
              </div>

              <!-- Research Overview -->
              <div class="research-section">
                <h3>The Research in Numbers</h3>

                <div class="stats-grid">
                  <div class="stat-card">
                    <div class="stat-number">535,236</div>
                    <div class="stat-label">Videos Analyzed</div>
                  </div>
                  <div class="stat-card">
                    <div class="stat-number">67,987</div>
                    <div class="stat-label">
                      Videos with Protected Attributes
                    </div>
                  </div>
                  <div class="stat-card">
                    <div class="stat-number">92.6%</div>
                    <div class="stat-label">Best Model Accuracy (BERT)</div>
                  </div>
                  <div class="stat-card highlight-stat">
                    <div class="stat-number">-12.6%</div>
                    <div class="stat-label">
                      Accuracy Gap for Black Women (Baseline)
                    </div>
                  </div>
                </div>
              </div>

              <!-- Dataset Composition -->
              <div class="research-section">
                <h3>Dataset Composition</h3>
                <p>
                  Half a million videos spanning multiple platforms, enriched
                  with intersectional demographic labels extracted via NLP.
                  Protected attributes include race/ethnicity, gender identity,
                  and sexuality markers.
                </p>

                <div class="data-breakdown">
                  <div class="breakdown-item">
                    <span class="breakdown-label">Black creators</span>
                    <div class="breakdown-bar">
                      <div
                        class="bar-fill"
                        style="
                          width: 47.5%;
                          background: linear-gradient(90deg, #dc2626, #ef4444);
                        "
                      ></div>
                      <span class="bar-value">25,415 (47.5%)</span>
                    </div>
                  </div>
                  <div class="breakdown-item">
                    <span class="breakdown-label">Asian creators</span>
                    <div class="breakdown-bar">
                      <div
                        class="bar-fill"
                        style="
                          width: 27.7%;
                          background: linear-gradient(90deg, #7b3db8, #9b6fcc);
                        "
                      ></div>
                      <span class="bar-value">14,831 (27.7%)</span>
                    </div>
                  </div>
                  <div class="breakdown-item">
                    <span class="breakdown-label">White creators</span>
                    <div class="breakdown-bar">
                      <div
                        class="bar-fill"
                        style="
                          width: 20.8%;
                          background: linear-gradient(90deg, #14b8a6, #2dd4bf);
                        "
                      ></div>
                      <span class="bar-value">11,140 (20.8%)</span>
                    </div>
                  </div>
                  <div class="breakdown-item">
                    <span class="breakdown-label">Latina creators</span>
                    <div class="breakdown-bar">
                      <div
                        class="bar-fill"
                        style="
                          width: 17.9%;
                          background: linear-gradient(90deg, #f59e0b, #fbbf24);
                        "
                      ></div>
                      <span class="bar-value">9,562 (17.9%)</span>
                    </div>
                  </div>
                  <div class="breakdown-item highlight-breakdown">
                    <span class="breakdown-label"
                      >Intersectional Black Women</span
                    >
                    <div class="breakdown-bar">
                      <div
                        class="bar-fill"
                        style="
                          width: 8.1%;
                          background: linear-gradient(90deg, #f43f5e, #fb7185);
                        "
                      ></div>
                      <span class="bar-value">4,360 (8.1%)</span>
                    </div>
                  </div>
                </div>
              </div>

              <!-- Key Findings -->
              <div class="research-section findings-section">
                <h3>Key Findings: The Bias is Real</h3>

                <!-- Finding 1: Sexualization -->
                <div class="finding-card critical">
                  <div class="finding-header">
                    <span class="finding-icon">üö®</span>
                    <h4>Extreme Sexualization Patterns</h4>
                  </div>
                  <div class="finding-content">
                    <p>
                      <strong
                        >Asian women's content is sexualized 99.5% of the
                        time</strong
                      >
                      in metadata and tags. Not a typo. Ninety-nine point five
                      percent. Black women: 77.6%. White women: 95.7%. This
                      isn't just bias ‚Äî it's systematic dehumanization encoded
                      in algorithmic categorization.
                    </p>
                    <div class="finding-metrics">
                      <div class="metric">
                        <span class="metric-label">Asian Women</span>
                        <span class="metric-value critical">99.5%</span>
                      </div>
                      <div class="metric">
                        <span class="metric-label">White Women</span>
                        <span class="metric-value critical">95.7%</span>
                      </div>
                      <div class="metric">
                        <span class="metric-label">Black Women</span>
                        <span class="metric-value warning">77.6%</span>
                      </div>
                    </div>
                  </div>
                </div>

                <!-- Finding 2: Animalization -->
                <div class="finding-card warning">
                  <div class="finding-header">
                    <span class="finding-icon">‚ö†Ô∏è</span>
                    <h4>Dehumanizing Stereotypes</h4>
                  </div>
                  <div class="finding-content">
                    <p>
                      Black creators face
                      <strong>54.2% animalization</strong> in content
                      descriptors (stereotypes comparing people to animals).
                      Latina creators show the highest rates of
                      relationship/role-based stereotyping at 25.1%. These
                      aren't accidents ‚Äî they're racist tropes embedded in
                      training data.
                    </p>
                    <div class="finding-metrics">
                      <div class="metric">
                        <span class="metric-label">Black: Animalization</span>
                        <span class="metric-value warning">54.2%</span>
                      </div>
                      <div class="metric">
                        <span class="metric-label"
                          >Latina: Relationship Stereotypes</span
                        >
                        <span class="metric-value warning">25.1%</span>
                      </div>
                    </div>
                  </div>
                </div>

                <!-- Finding 3: Engagement Disparities -->
                <div class="finding-card info">
                  <div class="finding-header">
                    <span class="finding-icon">üìâ</span>
                    <h4>Algorithmic Suppression</h4>
                  </div>
                  <div class="finding-content">
                    <p>
                      Asian creators receive <strong>49% fewer views</strong> on
                      average compared to non-Asian creators (43,597 vs 85,630).
                      Lower ratings across the board for marginalized groups
                      suggests algorithmic ranking bias, not just audience
                      preference.
                    </p>
                    <div class="finding-metrics">
                      <div class="metric">
                        <span class="metric-label"
                          >Asian Creators: Avg Views</span
                        >
                        <span class="metric-value">43,597</span>
                      </div>
                      <div class="metric">
                        <span class="metric-label">Non-Asian: Avg Views</span>
                        <span class="metric-value">85,630</span>
                      </div>
                      <div class="metric">
                        <span class="metric-label">Disparity</span>
                        <span class="metric-value critical">-49%</span>
                      </div>
                    </div>
                  </div>
                </div>

                <!-- Finding 4: Model Performance Gaps -->
                <div class="finding-card warning">
                  <div class="finding-header">
                    <span class="finding-icon">‚öñÔ∏è</span>
                    <h4>Classification Accuracy Gaps</h4>
                  </div>
                  <div class="finding-content">
                    <p>
                      The baseline Random Forest model shows
                      <strong>12.6% lower accuracy for Black women</strong>
                      compared to White women. Asian women face 8.8% accuracy
                      disparity. These aren't small differences ‚Äî they're
                      material harms affecting real people's livelihoods.
                    </p>
                    <div class="finding-metrics">
                      <div class="metric">
                        <span class="metric-label">Black Women</span>
                        <span class="metric-value critical">-12.6%</span>
                      </div>
                      <div class="metric">
                        <span class="metric-label">Asian Women</span>
                        <span class="metric-value warning">-8.8%</span>
                      </div>
                      <div class="metric">
                        <span class="metric-label">Latina Women</span>
                        <span class="metric-value warning">-3.2%</span>
                      </div>
                    </div>
                  </div>
                </div>
              </div>

              <!-- Methodology -->
              <div class="research-section">
                <h3>Technical Approach</h3>

                <div class="methodology-grid">
                  <div class="method-card">
                    <h4>1. Data Engineering</h4>
                    <ul>
                      <li>
                        Extracted metadata from 535K+ videos using Python
                        (Pandas, NumPy)
                      </li>
                      <li>
                        NLP-based demographic attribute extraction with regex +
                        spaCy
                      </li>
                      <li>
                        Created intersectional labels (race √ó gender √ó
                        sexuality)
                      </li>
                      <li>
                        Engineered 49 features including stereotype markers and
                        harm categories
                      </li>
                    </ul>
                  </div>

                  <div class="method-card">
                    <h4>2. Exploratory Analysis</h4>
                    <ul>
                      <li>
                        Quantified representation imbalances (Gini coefficient:
                        0.77)
                      </li>
                      <li>
                        Measured harm category prevalence across protected
                        groups
                      </li>
                      <li>
                        Analyzed engagement disparities (views, ratings) via
                        statistical tests
                      </li>
                      <li>
                        Identified stereotype co-occurrence patterns using PMI
                      </li>
                    </ul>
                  </div>

                  <div class="method-card">
                    <h4>3. Model Development</h4>
                    <ul>
                      <li>
                        <strong>Baseline:</strong> Random Forest (80.5%
                        accuracy)
                      </li>
                      <li>
                        <strong>Advanced:</strong> BERT transformer (92.6%
                        accuracy, 0.871 F1)
                      </li>
                      <li>Hyperparameter tuning with cross-validation</li>
                      <li>SHAP analysis for model interpretability</li>
                    </ul>
                  </div>

                  <div class="method-card">
                    <h4>4. Fairness Evaluation</h4>
                    <ul>
                      <li>
                        Demographic Parity, Equal Opportunity, Disparate Impact
                        Ratio
                      </li>
                      <li>Per-group accuracy, precision, recall, F1 scores</li>
                      <li>
                        Statistical significance testing (permutation tests)
                      </li>
                      <li>
                        Intersectional analysis (Black women as test case)
                      </li>
                    </ul>
                  </div>

                  <div class="method-card">
                    <h4>5. Bias Mitigation</h4>
                    <ul>
                      <li>
                        <strong>Pre-processing:</strong> Reweighting (Fairlearn)
                        ‚Üí -10.8% gap
                      </li>
                      <li>
                        <strong>In-processing:</strong> Exponentiated Gradient
                        with DP ‚Üí -4.6% gap
                      </li>
                      <li>
                        <strong>Post-processing:</strong> Threshold optimization
                        ‚Üí -9.0% gap
                      </li>
                      <li>
                        Pareto frontier analysis (accuracy vs fairness
                        trade-offs)
                      </li>
                    </ul>
                  </div>

                  <div class="method-card">
                    <h4>6. Validation & Testing</h4>
                    <ul>
                      <li>Train/test/validation splits with stratification</li>
                      <li>Gold standard evaluation set for quality control</li>
                      <li>Robustness checks on multiple random seeds</li>
                      <li>
                        Self-checks on all analysis outputs for reproducibility
                      </li>
                    </ul>
                  </div>
                </div>
              </div>

              <!-- Mitigation Results -->
              <div class="research-section">
                <h3>Solutions: Bias Can Be Reduced</h3>
                <p>
                  I tested three bias mitigation strategies. The best approach
                  (in-processing with demographic parity constraints) reduced
                  the accuracy gap for Black women from
                  <strong>-12.6% to -4.6%</strong> ‚Äî a 63% improvement. It's not
                  perfect, but it proves fairness interventions work.
                </p>

                <div class="mitigation-comparison">
                  <div class="comparison-item">
                    <div class="comparison-label">Baseline RF</div>
                    <div class="comparison-bar">
                      <div class="bar-segment bad" style="width: 100%">
                        <span>-12.6% accuracy gap</span>
                      </div>
                    </div>
                  </div>
                  <div class="comparison-item">
                    <div class="comparison-label">Reweighted RF</div>
                    <div class="comparison-bar">
                      <div class="bar-segment warning" style="width: 85.7%">
                        <span>-10.8% gap (14% improvement)</span>
                      </div>
                    </div>
                  </div>
                  <div class="comparison-item">
                    <div class="comparison-label">Post-Processing</div>
                    <div class="comparison-bar">
                      <div class="bar-segment ok" style="width: 71.4%">
                        <span>-9.0% gap (29% improvement)</span>
                      </div>
                    </div>
                  </div>
                  <div class="comparison-item highlight-comparison">
                    <div class="comparison-label">In-Processing (EG + DP)</div>
                    <div class="comparison-bar">
                      <div class="bar-segment good" style="width: 36.5%">
                        <span>-4.6% gap (63% improvement!) ‚ú®</span>
                      </div>
                    </div>
                  </div>
                </div>

                <div class="mitigation-note">
                  <strong>Trade-off:</strong> The best fairness intervention
                  reduced overall accuracy from 80.5% to 74.8% ‚Äî a 5.7
                  percentage point drop. But here's the thing: if your system is
                  90% accurate for white people and 60% accurate for Black
                  people, it's not "90% accurate" ‚Äî it's discriminatory.
                  Fairness isn't a nice-to-have; it's a requirement for ethical
                  deployment.
                </div>
              </div>

              <!-- Tech Stack -->
              <div class="tech-stack-section">
                <h4>Full Tech Stack</h4>
                <div class="tech-tags">
                  <span class="tech-tag">Python</span>
                  <span class="tech-tag">Pandas</span>
                  <span class="tech-tag">NumPy</span>
                  <span class="tech-tag">Scikit-learn</span>
                  <span class="tech-tag">PyTorch</span>
                  <span class="tech-tag">Transformers (HuggingFace)</span>
                  <span class="tech-tag">BERT</span>
                  <span class="tech-tag">Fairlearn</span>
                  <span class="tech-tag">AIF360</span>
                  <span class="tech-tag">SHAP</span>
                  <span class="tech-tag">Matplotlib</span>
                  <span class="tech-tag">Seaborn</span>
                  <span class="tech-tag">spaCy</span>
                  <span class="tech-tag">NLTK</span>
                  <span class="tech-tag">Statsmodels</span>
                </div>
              </div>

              <!-- Links -->
              <div class="project-links">
                <a
                  href="https://github.com/louiseluli"
                  class="btn btn-primary"
                  target="_blank"
                  rel="noopener noreferrer"
                >
                  View Research Code
                  <svg
                    xmlns="http://www.w3.org/2000/svg"
                    width="16"
                    height="16"
                    viewBox="0 0 24 24"
                    fill="none"
                    stroke="currentColor"
                    stroke-width="2"
                  >
                    <path
                      d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"
                    ></path>
                    <polyline points="15 3 21 3 21 9"></polyline>
                    <line x1="10" y1="14" x2="21" y2="3"></line>
                  </svg>
                </a>
                <button class="btn btn-secondary" disabled>
                  Full Paper (Coming Soon)
                </button>
              </div>
            </div>

            <!-- Visualization Column -->
            <div
              class="featured-visual"
              data-aos="fade-left"
              data-aos-delay="200"
            >
              <div class="visual-container">
                <!-- SVG Data Visualization -->
                <svg
                  class="data-viz"
                  viewBox="0 0 400 500"
                  xmlns="http://www.w3.org/2000/svg"
                >
                  <!-- Title -->
                  <text x="200" y="30" text-anchor="middle" class="viz-title">
                    Accuracy by Demographic Group
                  </text>

                  <!-- Baseline Model -->
                  <text x="20" y="70" class="viz-subtitle">
                    Baseline Model (Random Forest)
                  </text>

                  <!-- White Women (baseline) -->
                  <rect
                    x="20"
                    y="85"
                    width="240"
                    height="30"
                    fill="#14B8A6"
                    rx="4"
                  />
                  <text x="270" y="105" class="viz-label">
                    White Women: 70.7%
                  </text>

                  <!-- Black Women -->
                  <rect
                    x="20"
                    y="125"
                    width="200"
                    height="30"
                    fill="#DC2626"
                    rx="4"
                  />
                  <text x="230" y="145" class="viz-label">
                    Black Women: 58.1% (-12.6%)
                  </text>

                  <!-- Asian Women -->
                  <rect
                    x="20"
                    y="165"
                    width="215"
                    height="30"
                    fill="#F59E0B"
                    rx="4"
                  />
                  <text x="245" y="185" class="viz-label">
                    Asian Women: 61.9% (-8.8%)
                  </text>

                  <!-- Latina Women -->
                  <rect
                    x="20"
                    y="205"
                    width="232"
                    height="30"
                    fill="#7B3DB8"
                    rx="4"
                  />
                  <text x="262" y="225" class="viz-label">
                    Latina Women: 67.5% (-3.2%)
                  </text>

                  <!-- Best Mitigation -->
                  <text x="20" y="270" class="viz-subtitle">
                    After Mitigation (In-Processing)
                  </text>

                  <!-- White Women (after) -->
                  <rect
                    x="20"
                    y="285"
                    width="240"
                    height="30"
                    fill="#14B8A6"
                    rx="4"
                  />
                  <text x="270" y="305" class="viz-label">
                    White Women: 91.0%
                  </text>

                  <!-- Black Women (after) -->
                  <rect
                    x="20"
                    y="325"
                    width="235"
                    height="30"
                    fill="#059669"
                    rx="4"
                  />
                  <text x="265" y="345" class="viz-label">
                    Black Women: 86.4% (-4.6%)
                  </text>

                  <!-- Improvement Arrow -->
                  <g transform="translate(200, 380)">
                    <circle r="40" fill="#FFC043" opacity="0.2" />
                    <text y="8" text-anchor="middle" class="viz-highlight">
                      63%
                    </text>
                    <text
                      y="25"
                      text-anchor="middle"
                      class="viz-highlight-small"
                    >
                      improvement
                    </text>
                  </g>

                  <!-- Stats Footer -->
                  <text x="200" y="460" text-anchor="middle" class="viz-footer">
                    Dataset: 535,236 videos | Test Set: 107,047
                  </text>
                  <text x="200" y="480" text-anchor="middle" class="viz-footer">
                    Fairness Metric: Demographic Parity Difference
                  </text>
                </svg>

                <!-- Key Insight Box -->
                <div class="insight-box">
                  <h5>üí° Key Insight</h5>
                  <p>
                    By enforcing demographic parity during training, we reduced
                    the worst-case accuracy gap by 63% while maintaining 91%
                    overall accuracy. The cost? A 5-point accuracy drop ‚Äî a
                    price worth paying for fairness.
                  </p>
                </div>
              </div>
            </div>

            <!-- Additional Data Visualizations -->
            <!-- Visualization 1: Harm Categories Breakdown -->
            <div
              class="data-viz-section"
              data-aos="fade-up"
              data-aos-delay="300"
            >
              <div class="viz-card">
                <h3 class="viz-card-title">Stereotype Categories by Group</h3>
                <p class="viz-card-subtitle">
                  Percentage of content tagged with harmful stereotype markers
                  across racial/ethnic groups
                </p>

                <svg
                  class="harm-viz"
                  viewBox="0 0 800 450"
                  xmlns="http://www.w3.org/2000/svg"
                >
                  <!-- Title -->
                  <text x="400" y="30" text-anchor="middle" class="viz-title">
                    Sexualization Rates Are Astronomical
                  </text>

                  <!-- Legend -->
                  <g transform="translate(550, 60)">
                    <rect x="0" y="0" width="15" height="15" fill="#DC2626" />
                    <text x="20" y="12" class="viz-legend">Sexualization</text>

                    <rect x="0" y="25" width="15" height="15" fill="#F59E0B" />
                    <text x="20" y="37" class="viz-legend">Animalization</text>

                    <rect x="0" y="50" width="15" height="15" fill="#7B3DB8" />
                    <text x="20" y="62" class="viz-legend">
                      Relationship Stereotypes
                    </text>
                  </g>

                  <!-- Asian Women -->
                  <g transform="translate(80, 100)">
                    <text x="0" y="0" class="viz-group-label">Asian Women</text>

                    <!-- Sexualization: 99.5% -->
                    <rect
                      x="0"
                      y="10"
                      width="398"
                      height="35"
                      fill="#DC2626"
                      rx="4"
                    />
                    <text x="405" y="32" class="viz-bar-label">99.5%</text>

                    <!-- Animalization: 32.9% -->
                    <rect
                      x="0"
                      y="50"
                      width="132"
                      height="25"
                      fill="#F59E0B"
                      rx="4"
                    />
                    <text x="138" y="67" class="viz-bar-label-sm">32.9%</text>

                    <!-- Relationship: 13.8% -->
                    <rect
                      x="0"
                      y="80"
                      width="55"
                      height="25"
                      fill="#7B3DB8"
                      rx="4"
                    />
                    <text x="61" y="97" class="viz-bar-label-sm">13.8%</text>
                  </g>

                  <!-- Black Women -->
                  <g transform="translate(80, 220)">
                    <text x="0" y="0" class="viz-group-label">Black Women</text>

                    <!-- Sexualization: 77.6% -->
                    <rect
                      x="0"
                      y="10"
                      width="310"
                      height="35"
                      fill="#DC2626"
                      rx="4"
                    />
                    <text x="317" y="32" class="viz-bar-label">77.6%</text>

                    <!-- Animalization: 54.2% -->
                    <rect
                      x="0"
                      y="50"
                      width="217"
                      height="25"
                      fill="#F59E0B"
                      rx="4"
                    />
                    <text x="223" y="67" class="viz-bar-label-sm">54.2%</text>

                    <!-- Relationship: 14.1% -->
                    <rect
                      x="0"
                      y="80"
                      width="56"
                      height="25"
                      fill="#7B3DB8"
                      rx="4"
                    />
                    <text x="62" y="97" class="viz-bar-label-sm">14.1%</text>
                  </g>

                  <!-- White Women -->
                  <g transform="translate(80, 340)">
                    <text x="0" y="0" class="viz-group-label">White Women</text>

                    <!-- Sexualization: 95.7% -->
                    <rect
                      x="0"
                      y="10"
                      width="383"
                      height="35"
                      fill="#DC2626"
                      rx="4"
                    />
                    <text x="390" y="32" class="viz-bar-label">95.7%</text>

                    <!-- Animalization: 55.0% -->
                    <rect
                      x="0"
                      y="50"
                      width="220"
                      height="25"
                      fill="#F59E0B"
                      rx="4"
                    />
                    <text x="226" y="67" class="viz-bar-label-sm">55.0%</text>

                    <!-- Relationship: 15.7% -->
                    <rect
                      x="0"
                      y="80"
                      width="63"
                      height="25"
                      fill="#7B3DB8"
                      rx="4"
                    />
                    <text x="69" y="97" class="viz-bar-label-sm">15.7%</text>
                  </g>
                </svg>

                <div class="viz-insight">
                  <strong>Critical Finding:</strong> Asian women's content is
                  sexualized 99.5% of the time. Black women face the highest
                  animalization rates at 54.2%. These aren't edge cases ‚Äî
                  they're systematic patterns of dehumanization.
                </div>
              </div>
            </div>

            <!-- Visualization 2: Engagement Disparities -->
            <div
              class="data-viz-section"
              data-aos="fade-up"
              data-aos-delay="400"
            >
              <div class="viz-card">
                <h3 class="viz-card-title">
                  Algorithmic Suppression is Measurable
                </h3>
                <p class="viz-card-subtitle">
                  Average views and ratings show systematic disadvantages for
                  marginalized creators
                </p>

                <svg
                  class="engagement-viz"
                  viewBox="0 0 700 400"
                  xmlns="http://www.w3.org/2000/svg"
                >
                  <!-- Title -->
                  <text x="350" y="30" text-anchor="middle" class="viz-title">
                    Views Gap: Asian vs. Non-Asian Creators
                  </text>

                  <!-- Non-Asian Creators Bar -->
                  <g transform="translate(100, 80)">
                    <text x="0" y="0" class="viz-group-label">
                      Non-Asian Creators
                    </text>
                    <rect
                      x="0"
                      y="10"
                      width="500"
                      height="50"
                      fill="#14B8A6"
                      rx="4"
                    />
                    <text
                      x="250"
                      y="42"
                      text-anchor="middle"
                      class="viz-bar-text"
                    >
                      85,630 avg views
                    </text>
                  </g>

                  <!-- Asian Creators Bar -->
                  <g transform="translate(100, 180)">
                    <text x="0" y="0" class="viz-group-label">
                      Asian Creators
                    </text>
                    <rect
                      x="0"
                      y="10"
                      width="255"
                      height="50"
                      fill="#DC2626"
                      rx="4"
                    />
                    <text
                      x="127"
                      y="42"
                      text-anchor="middle"
                      class="viz-bar-text"
                    >
                      43,597 avg views
                    </text>
                  </g>

                  <!-- Gap Indicator -->
                  <g transform="translate(350, 280)">
                    <circle r="60" fill="#FFC043" opacity="0.2" />
                    <text
                      y="-10"
                      text-anchor="middle"
                      class="viz-highlight"
                      style="font-size: 36px"
                    >
                      -49%
                    </text>
                    <text
                      y="15"
                      text-anchor="middle"
                      class="viz-highlight-small"
                      style="font-size: 14px"
                    >
                      DISPARITY
                    </text>
                  </g>

                  <!-- Footer note -->
                  <text x="350" y="380" text-anchor="middle" class="viz-footer">
                    This isn't audience preference ‚Äî it's algorithmic ranking
                    bias
                  </text>
                </svg>
              </div>
            </div>

            <!-- Visualization 3: Model Performance Comparison -->
            <div
              class="data-viz-section"
              data-aos="fade-up"
              data-aos-delay="500"
            >
              <div class="viz-card">
                <h3 class="viz-card-title">
                  Machine Learning Models Can Do Better
                </h3>
                <p class="viz-card-subtitle">
                  Comparing baseline Random Forest vs. BERT transformer
                  performance across groups
                </p>

                <svg
                  class="model-comparison-viz"
                  viewBox="0 0 800 500"
                  xmlns="http://www.w3.org/2000/svg"
                >
                  <!-- Title -->
                  <text x="400" y="30" text-anchor="middle" class="viz-title">
                    Classification Accuracy by Model
                  </text>

                  <!-- Legend -->
                  <g transform="translate(250, 60)">
                    <rect x="0" y="0" width="20" height="20" fill="#7B3DB8" />
                    <text x="28" y="15" class="viz-legend">
                      Random Forest (Baseline)
                    </text>

                    <rect x="220" y="0" width="20" height="20" fill="#10B981" />
                    <text x="248" y="15" class="viz-legend">
                      BERT Transformer
                    </text>
                  </g>

                  <!-- Asian Women -->
                  <g transform="translate(100, 120)">
                    <text x="0" y="20" class="viz-group-label">
                      Asian Women
                    </text>
                    <!-- RF: 79.5% -->
                    <rect
                      x="200"
                      y="5"
                      width="159"
                      height="30"
                      fill="#7B3DB8"
                      rx="4"
                    />
                    <text
                      x="285"
                      y="26"
                      text-anchor="middle"
                      class="viz-bar-text-white"
                    >
                      79.5%
                    </text>
                    <!-- BERT: 91.6% -->
                    <rect
                      x="200"
                      y="40"
                      width="183"
                      height="30"
                      fill="#10B981"
                      rx="4"
                    />
                    <text
                      x="295"
                      y="61"
                      text-anchor="middle"
                      class="viz-bar-text-white"
                    >
                      91.6%
                    </text>
                  </g>

                  <!-- Black Women -->
                  <g transform="translate(100, 220)">
                    <text x="0" y="20" class="viz-group-label">
                      Black Women
                    </text>
                    <!-- RF: 83.3% -->
                    <rect
                      x="200"
                      y="5"
                      width="167"
                      height="30"
                      fill="#7B3DB8"
                      rx="4"
                    />
                    <text
                      x="285"
                      y="26"
                      text-anchor="middle"
                      class="viz-bar-text-white"
                    >
                      83.3%
                    </text>
                    <!-- BERT: 96.0% -->
                    <rect
                      x="200"
                      y="40"
                      width="192"
                      height="30"
                      fill="#10B981"
                      rx="4"
                    />
                    <text
                      x="300"
                      y="61"
                      text-anchor="middle"
                      class="viz-bar-text-white"
                    >
                      96.0%
                    </text>
                  </g>

                  <!-- Latina Women -->
                  <g transform="translate(100, 320)">
                    <text x="0" y="20" class="viz-group-label">
                      Latina Women
                    </text>
                    <!-- RF: 73.9% -->
                    <rect
                      x="200"
                      y="5"
                      width="148"
                      height="30"
                      fill="#7B3DB8"
                      rx="4"
                    />
                    <text
                      x="275"
                      y="26"
                      text-anchor="middle"
                      class="viz-bar-text-white"
                    >
                      73.9%
                    </text>
                    <!-- BERT: 86.7% -->
                    <rect
                      x="200"
                      y="40"
                      width="173"
                      height="30"
                      fill="#10B981"
                      rx="4"
                    />
                    <text
                      x="290"
                      y="61"
                      text-anchor="middle"
                      class="viz-bar-text-white"
                    >
                      86.7%
                    </text>
                  </g>

                  <!-- White Women -->
                  <g transform="translate(100, 420)">
                    <text x="0" y="20" class="viz-group-label">
                      White Women
                    </text>
                    <!-- RF: 70.7% -->
                    <rect
                      x="200"
                      y="5"
                      width="141"
                      height="30"
                      fill="#7B3DB8"
                      rx="4"
                    />
                    <text
                      x="272"
                      y="26"
                      text-anchor="middle"
                      class="viz-bar-text-white"
                    >
                      70.7%
                    </text>
                    <!-- BERT: 91.0% -->
                    <rect
                      x="200"
                      y="40"
                      width="182"
                      height="30"
                      fill="#10B981"
                      rx="4"
                    />
                    <text
                      x="295"
                      y="61"
                      text-anchor="middle"
                      class="viz-bar-text-white"
                    >
                      91.0%
                    </text>
                  </g>

                  <!-- Scale reference line -->
                  <line
                    x1="200"
                    y1="100"
                    x2="200"
                    y2="480"
                    stroke="#94A3B8"
                    stroke-width="1"
                    stroke-dasharray="4,4"
                  />
                </svg>

                <div class="viz-insight">
                  <strong>Key Takeaway:</strong> BERT dramatically outperforms
                  Random Forest across all groups, with Black women seeing the
                  biggest improvement (83.3% ‚Üí 96.0%). Better models = fairer
                  outcomes.
                </div>
              </div>
            </div>

            <!-- Visualization 4: Intersectional Analysis -->
            <div
              class="data-viz-section"
              data-aos="fade-up"
              data-aos-delay="600"
            >
              <div class="viz-card">
                <h3 class="viz-card-title">Intersectionality Matters</h3>
                <p class="viz-card-subtitle">
                  Black women at the intersection of race and gender face
                  compounded discrimination
                </p>

                <div class="intersectional-grid">
                  <!-- Stat 1 -->
                  <div class="intersect-stat">
                    <div class="intersect-number">4,360</div>
                    <div class="intersect-label">
                      Intersectional Black Women in Dataset
                    </div>
                    <div class="intersect-percent">
                      8.1% of protected group content
                    </div>
                  </div>

                  <!-- Stat 2 -->
                  <div class="intersect-stat critical">
                    <div class="intersect-number">81.4%</div>
                    <div class="intersect-label">Sexualization Rate</div>
                    <div class="intersect-note">
                      Higher than Black men (77.6%) or women overall (10.2%)
                    </div>
                  </div>

                  <!-- Stat 3 -->
                  <div class="intersect-stat">
                    <div class="intersect-number">54.1%</div>
                    <div class="intersect-label">Animalization Markers</div>
                    <div class="intersect-note">
                      Dehumanizing stereotypes in metadata
                    </div>
                  </div>

                  <!-- Stat 4 -->
                  <div class="intersect-stat warning">
                    <div class="intersect-number">-12.6%</div>
                    <div class="intersect-label">
                      Accuracy Gap (Baseline Model)
                    </div>
                    <div class="intersect-note">
                      Worst performance disparity across all groups
                    </div>
                  </div>
                </div>

                <div class="viz-insight">
                  <strong>This is Why Intersectionality Matters:</strong> You
                  can't understand algorithmic bias by looking at race OR gender
                  alone. Black women face unique patterns of discrimination that
                  emerge specifically at the intersection ‚Äî and our fairness
                  interventions reduced their accuracy gap from -12.6% to -4.6%.
                </div>
              </div>
            </div>
          </div>
        </div>
      </section>

      <!-- ==========================================================================
         PROJECT GRID
         ========================================================================== -->
      <section class="projects-grid section section-alt">
        <div class="container">
          <!-- Project Card: Cinema Analysis - DETAILED VERSION -->
          <article
            class="project-card"
            data-category="ml nlp"
            data-aos="fade-up"
          >
            <div class="project-card-header">
              <div class="project-meta">
                <span class="project-type">Machine Learning ‚Ä¢ Data Mining</span>
                <span class="project-year">2024-2025</span>
              </div>
              <h3 class="project-card-title">
                Cinema Through Data: Cultural Analysis (1915-1960)
              </h3>
              <p class="project-card-tagline">
                Large-scale cultural data mining meets film history ‚Äî 140,000+
                movies, one massive pipeline
              </p>
            </div>

            <div class="project-card-body">
              <p>
                What can 140,000 old movies tell you about culture,
                representation, and power dynamics? I built a full-stack data
                product to find out ‚Äî from scraping IMDb datasets to training ML
                models that actually understand film. This wasn't just an
                academic exercise; it's a production-grade system with an 800+
                line Streamlit app that lets you explore decades of cinema data.
              </p>

              <h4>The Scale</h4>
              <div class="project-stats">
                <div class="project-stat">
                  <span class="stat-num">140,000+</span>
                  <span class="stat-label">Unique film titles processed</span>
                </div>
                <div class="project-stat">
                  <span class="stat-num">77,000</span>
                  <span class="stat-label">Graph nodes (people, films)</span>
                </div>
                <div class="project-stat">
                  <span class="stat-num">313,000</span>
                  <span class="stat-label">Graph edges (relationships)</span>
                </div>
                <div class="project-stat highlight">
                  <span class="stat-num">98.71%</span>
                  <span class="stat-label"
                    >Final model accuracy (LightGBM)</span
                  >
                </div>
              </div>

              <h4>Data Engineering Pipeline</h4>
              <ul>
                <li>
                  <strong>ETL Process:</strong> Processed 6 IMDb non-commercial
                  datasets using memory-efficient Python pipelines with custom
                  chunked data loaders. Normalized schema into SQLite database
                  with proper foreign key relationships
                </li>
                <li>
                  <strong>Data Enrichment:</strong> Integrated IMDb, TMDB API,
                  OMDB API, and Wikidata for comprehensive film metadata ‚Äî plot
                  summaries, cast, crew, ratings, box office
                </li>
                <li>
                  <strong>Graph Construction:</strong> Built bipartite network
                  connecting films to people (actors, directors, writers) with
                  77k nodes and 313k edges. Used NetworkX for graph metrics and
                  community detection
                </li>
                <li>
                  <strong>Text Processing:</strong> Applied TF-IDF vectorization
                  on plot summaries, titles, and genres. Created custom
                  tokenization pipeline handling historical language and
                  spelling variations
                </li>
              </ul>

              <h4>Machine Learning Implementation</h4>
              <ul>
                <li>
                  <strong>Hybrid Recommender System:</strong> Combined
                  collaborative filtering (user-item matrices), content-based
                  filtering (TF-IDF similarity), and graph-based approaches
                  (PageRank, betweenness centrality). Ensemble model weights
                  learned via hyperparameter tuning
                </li>
                <li>
                  <strong>Deep Learning Embeddings:</strong> Trained autoencoder
                  neural network to compress 32,677 films into 128-dimensional
                  dense representations. Used embeddings for similarity search
                  via FAISS indexing (nearest neighbor queries in &lt; 10ms)
                </li>
                <li>
                  <strong>Clustering Analysis:</strong> Implemented K-Means,
                  DBSCAN, and Agglomerative clustering with silhouette analysis.
                  Discovered meaningful film genre groupings and temporal
                  patterns across decades
                </li>
                <li>
                  <strong>Classification Pipeline:</strong> Built LightGBM model
                  combining text features (TF-IDF), numeric features (ratings,
                  runtime), and graph features (centrality metrics). Achieved
                  98.71% test accuracy with proper train/validation/test splits
                </li>
              </ul>

              <h4>Innovation: Cross-Lingual Title Mapping</h4>
              <p>
                Created a novel title mapping system for robust cross-lingual
                film identification. Because "La Dolce Vita" and "The Sweet
                Life" should be recognized as the same movie, right? System
                handles:
              </p>
              <ul>
                <li>Translation variations across 30+ languages</li>
                <li>Title changes across regions and time periods</li>
                <li>
                  Fuzzy matching with edit distance and phonetic algorithms
                </li>
                <li>Disambiguation using year, director, and cast metadata</li>
              </ul>

              <h4>Production Application</h4>
              <ul>
                <li>
                  <strong>Streamlit UI:</strong> Built 800+ line interactive web
                  application with multiple views ‚Äî film search, recommendation
                  engine, network visualization, statistical dashboards
                </li>
                <li>
                  <strong>Real-Time Queries:</strong> Optimized SQLite queries
                  with proper indexing. Average search response time &lt; 100ms
                  for full-text queries across 140k records
                </li>
                <li>
                  <strong>Visualization Suite:</strong> Interactive plots with
                  Plotly ‚Äî temporal trends, genre evolution, collaboration
                  networks, rating distributions
                </li>
                <li>
                  <strong>Export Functionality:</strong> Users can download
                  filtered datasets, recommendation lists, and generated
                  embeddings in CSV/JSON formats
                </li>
              </ul>

              <h4>Technical Challenges Solved</h4>
              <ul>
                <li>
                  <strong>Memory Efficiency:</strong> IMDb datasets exceed 4GB.
                  Implemented chunked processing with generators to handle data
                  100x larger than RAM
                </li>
                <li>
                  <strong>Data Quality:</strong> Historical film data is messy ‚Äî
                  missing values, encoding errors, duplicate entries. Built
                  robust cleaning pipeline with validation rules and manual
                  spot-checks
                </li>
                <li>
                  <strong>Scalability:</strong> Graph algorithms (PageRank,
                  community detection) don't scale well. Used approximate
                  algorithms and sampling for graphs &gt; 100k edges
                </li>
                <li>
                  <strong>API Rate Limits:</strong> TMDB and OMDB APIs have
                  strict rate limits. Implemented caching, exponential backoff,
                  and prioritized enrichment for high-value films (classics,
                  popular titles)
                </li>
              </ul>

              <div class="project-impact">
                <h4>Why This Matters</h4>
                <p>
                  This project demonstrates end-to-end data product development
                  ‚Äî from raw data acquisition to production ML system. It
                  combines data engineering, machine learning, NLP, graph
                  analysis, and full-stack development. The result? A system
                  that makes 100 years of film history queryable, explorable,
                  and understandable through data.
                </p>
              </div>

              <div class="tech-stack">
                <h4>Full Tech Stack</h4>
                <div class="tech-tags">
                  <span class="tech-tag">Python</span>
                  <span class="tech-tag">Pandas</span>
                  <span class="tech-tag">NumPy</span>
                  <span class="tech-tag">Scikit-learn</span>
                  <span class="tech-tag">LightGBM</span>
                  <span class="tech-tag">TensorFlow</span>
                  <span class="tech-tag">Keras</span>
                  <span class="tech-tag">FAISS</span>
                  <span class="tech-tag">NetworkX</span>
                  <span class="tech-tag">SQLite</span>
                  <span class="tech-tag">Streamlit</span>
                  <span class="tech-tag">Plotly</span>
                  <span class="tech-tag">NLTK</span>
                  <span class="tech-tag">Requests</span>
                </div>
              </div>
            </div>

            <div class="project-card-footer">
              <a
                href="https://github.com/louiseluli"
                class="project-link"
                target="_blank"
                rel="noopener noreferrer"
              >
                View Code & Demo ‚Üí
              </a>
            </div>
          </article>

          <!-- Project Card: IDB Chatbot -->
          <article
            class="project-card"
            data-category="nlp tools"
            data-aos="fade-up"
            data-aos-delay="100"
          >
            <div class="project-card-header">
              <div class="project-meta">
                <span class="project-type">NLP & Infrastructure</span>
                <span class="project-year">Summer 2025</span>
              </div>
              <h3 class="project-card-title">
                AI Chatbot for Inter-American Development Bank
              </h3>
              <p class="project-card-tagline">
                Enterprise-grade semantic search at scale
              </p>
            </div>

            <div class="project-card-body">
              <p>
                Built an AI-powered chatbot for the IDB's Office of the
                Secretary that doesn't just keyword search ‚Äî it actually
                understands what you're asking and finds the right documents.
              </p>

              <h4>Technical Highlights</h4>
              <ul>
                <li>
                  <strong>Document Pipeline:</strong> Automated PDF ingestion
                  using PyPDF2/PyPDFLoader with metadata extraction
                </li>
                <li>
                  <strong>AI Integration:</strong> Azure OpenAI GPT-4o for
                  semantic parsing and smart metadata generation
                </li>
                <li>
                  <strong>Hybrid Search:</strong> Combined Hugging Face
                  embeddings (all-MiniLM-L6-v2) + FAISS for semantic search with
                  BM25 for keyword matching
                </li>
                <li>
                  <strong>Backend:</strong> C#/SQL RESTful API for real-time
                  queries and enterprise data integration
                </li>
                <li>
                  <strong>Smart Caching:</strong> Versioned JSON metadata cache
                  to optimize costs and LLM usage
                </li>
              </ul>

              <p>
                Result? Lightning-fast, accurate document retrieval that
                actually helps people find what they need instead of drowning in
                enterprise bureaucracy.
              </p>

              <div class="tech-stack">
                <div class="tech-tags">
                  <span class="tech-tag">Python</span>
                  <span class="tech-tag">C#</span>
                  <span class="tech-tag">SQL</span>
                  <span class="tech-tag">Azure OpenAI</span>
                  <span class="tech-tag">Hugging Face</span>
                  <span class="tech-tag">FAISS</span>
                  <span class="tech-tag">PyPDF2</span>
                </div>
              </div>
            </div>

            <div class="project-card-footer">
              <span class="project-status">Proprietary Project</span>
            </div>
          </article>

          <!-- Project Card: Search Engine Evaluation -->
          <article
            class="project-card"
            data-category="nlp"
            data-aos="fade-up"
            data-aos-delay="200"
          >
            <div class="project-card-header">
              <div class="project-meta">
                <span class="project-type">Information Retrieval</span>
                <span class="project-year">2024</span>
              </div>
              <h3 class="project-card-title">
                Search Engine Performance Analysis
              </h3>
              <p class="project-card-tagline">
                Making search suck less through systematic evaluation
              </p>
            </div>

            <div class="project-card-body">
              <p>
                Ever notice how search engines sometimes completely miss the
                point of your query? I built a framework to measure exactly how
                badly they're failing ‚Äî and where they can improve.
              </p>

              <h4>What I Did</h4>
              <ul>
                <li>
                  Created gold-standard evaluation dataset with 20 complex
                  queries across multiple formulation styles
                </li>
                <li>
                  Developed Python automation for precision/recall calculation
                  at various cutoffs (n=5, n=10)
                </li>
                <li>Identified systematic patterns in query performance</li>
                <li>
                  Provided actionable insights for search algorithm optimization
                </li>
              </ul>

              <p>
                The boring-but-important work of making sure people can actually
                find what they're looking for.
              </p>

              <div class="tech-stack">
                <div class="tech-tags">
                  <span class="tech-tag">Python</span>
                  <span class="tech-tag">Information Retrieval</span>
                  <span class="tech-tag">Evaluation Metrics</span>
                </div>
              </div>
            </div>

            <div class="project-card-footer">
              <a
                href="https://github.com/louiseluli"
                class="project-link"
                target="_blank"
                rel="noopener noreferrer"
              >
                View Methodology ‚Üí
              </a>
            </div>
          </article>
        </div>
      </section>

      <!-- ==========================================================================
         CALL TO ACTION
         ========================================================================== -->
      <section class="cta-section section">
        <div class="container text-center">
          <h2 class="cta-title" data-aos="fade-up">Want to See More?</h2>
          <p class="cta-text" data-aos="fade-up" data-aos-delay="100">
            I'm constantly working on new projects at the intersection of AI
            fairness, NLP, and ethical tech. Check out my GitHub for the latest
            code, or get in touch if you want to collaborate.
          </p>
          <div class="cta-buttons" data-aos="fade-up" data-aos-delay="200">
            <a
              href="https://github.com/louiseluli"
              target="_blank"
              rel="noopener noreferrer"
              class="btn btn-primary"
            >
              Browse GitHub
            </a>
            <a href="contact.html" class="btn btn-secondary">
              Let's Collaborate
            </a>
          </div>
        </div>
      </section>
    </main>

    <!-- ============================================================================
       FOOTER
       ============================================================================ -->
    <footer class="site-footer">
      <div class="container">
        <div class="footer-content">
          <div class="footer-brand">
            <p class="footer-tagline">
              Building algorithms that serve justice, not just efficiency.
            </p>
          </div>

          <nav class="footer-nav" aria-label="Footer navigation">
            <a href="about.html">About</a>
            <a href="experience.html">Experience</a>
            <a href="personal.html">Personal</a>
            <a href="projects.html">Projects</a>
            <a href="contact.html">Contact</a>
          </nav>

          <div class="footer-social">
            <a
              href="https://github.com/louiseluli"
              target="_blank"
              rel="noopener noreferrer"
              aria-label="GitHub"
            >
              <svg
                xmlns="http://www.w3.org/2000/svg"
                width="20"
                height="20"
                viewBox="0 0 24 24"
                fill="none"
                stroke="currentColor"
                stroke-width="2"
                stroke-linecap="round"
                stroke-linejoin="round"
              >
                <path
                  d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"
                ></path>
              </svg>
            </a>
            <a
              href="https://www.linkedin.com/in/louisesfer/"
              target="_blank"
              rel="noopener noreferrer"
              aria-label="LinkedIn"
            >
              <svg
                xmlns="http://www.w3.org/2000/svg"
                width="20"
                height="20"
                viewBox="0 0 24 24"
                fill="none"
                stroke="currentColor"
                stroke-width="2"
                stroke-linecap="round"
                stroke-linejoin="round"
              >
                <path
                  d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"
                ></path>
                <rect x="2" y="9" width="4" height="12"></rect>
                <circle cx="4" cy="4" r="2"></circle>
              </svg>
            </a>
          </div>
        </div>

        <div class="footer-bottom">
          <p>&copy; 2025 Louise Ferreira. Built with purpose and code.</p>
        </div>
      </div>
    </footer>

    <!-- ============================================================================
       SCRIPTS
       ============================================================================ -->
    <script src="assets/js/theme-toggle.js"></script>
    <script src="assets/js/navbar.js"></script>
    <script src="assets/js/project-filter.js"></script>

    <!-- AOS (Animate On Scroll) -->
    <script src="https://unpkg.com/aos@2.3.1/dist/aos.js"></script>
    <script>
      if (typeof AOS !== "undefined") {
        AOS.init({
          duration: 800,
          easing: "ease-in-out",
          once: true,
          offset: 100,
        });
      }
    </script>
    <!-- THEME TOGGLE BUTTON -->
    <button class="theme-toggle" id="themeToggle" aria-label="Toggle dark mode">
      <svg
        class="sun-icon"
        xmlns="http://www.w3.org/2000/svg"
        viewBox="0 0 24 24"
        fill="none"
        stroke="currentColor"
        stroke-width="2"
        stroke-linecap="round"
        stroke-linejoin="round"
      >
        <circle cx="12" cy="12" r="5"></circle>
        <line x1="12" y1="1" x2="12" y2="3"></line>
        <line x1="12" y1="21" x2="12" y2="23"></line>
        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
        <line x1="1" y1="12" x2="3" y2="12"></line>
        <line x1="21" y1="12" x2="23" y2="12"></line>
        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
      </svg>
      <svg
        class="moon-icon"
        xmlns="http://www.w3.org/2000/svg"
        viewBox="0 0 24 24"
        fill="none"
        stroke="currentColor"
        stroke-width="2"
        stroke-linecap="round"
        stroke-linejoin="round"
      >
        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
      </svg>
    </button>
  </body>
</html>
